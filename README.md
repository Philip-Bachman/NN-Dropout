NN-Dropout
==========

The code in this repository implements batch gradient-descent training for simple feedforward neural networks with dropout. The code is reasonably efficient, and permits selection of various activation functions among hidden/output nodes and selection of various loss functions at the output layer.
